# Multi-Label Text Classification Using Transformers and BERT

## Description
This repository contains code and resources for performing multi-label text classification using Transformer models, BERT, and RoBERTa. The project aims to provide a comprehensive framework for training and evaluating models on text data with multiple labels per instance, utilizing the Reuters dataset from NLTK.

### Usage
To run the project with different models, navigate to the respective model's directory and execute the `main.py` script. Ensure you have downloaded the Reuters dataset from NLTK.

1. **Clone the Repository**:
    ```bash
    git clone https://github.com/yourusername/Multi-Label-Text-Classification-Using-Transformers-and-BERT.git
    cd Multi-Label-Text-Classification-Using-Transformers-and-BERT
    pip install -r requirements.txt
    ```

2. **Running the Transformer Model**:
    ```bash
    cd Transformers
    python main.py
    ```

3. **Running the BERT Model**:
    ```bash
    cd BERT
    python main.py
    ```

4. **Running the RoBERTa Model**:
    ```bash
    cd RoBERTa
    python main.py
    ```


### License
This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for more details.
